{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5xeh5c595Kd"
      },
      "source": [
        "# Entwicklung eines Prototyps zur Münzzählung mithilfe von Bildverarbeitung und Machine Learning\n",
        "## Development of a prototype for coin counting using image processing and machine learning\n",
        "\n",
        "author:  Angmar3019 <br>\n",
        "date:    07.02.2023 <br>\n",
        "version: 1.0.0 <br>\n",
        "licence: GNU General Public License v3.0 <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Juaw2QZDsl_"
      },
      "source": [
        "## Clone repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HSkHDULJDjVk"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/Angmar3019/DHBW-Studienarbeit.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVgwJ74p-pBa"
      },
      "source": [
        "## Upload images and coco dataset\n",
        "\n",
        "Either you can take the provided images from me, then execute the first cell.\n",
        "\n",
        "If you want to use your own images, then execute the second cell and then upload your images to the folder `/data/images/` and save your coco dataset under `/data/result.json`.\n",
        "\n",
        "Then you can execute the other cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARZJFHlY_yjb"
      },
      "outputs": [],
      "source": [
        "# Using providet images\n",
        "!mkdir -p data/images\n",
        "!cp -r /content/DHBW-Studienarbeit/training/* /content/data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBJVcYHH-t_K"
      },
      "outputs": [],
      "source": [
        "# Using own images\n",
        "!mkdir -p data/images\n",
        "!cp /content/DHBW-Studienarbeit/training/label_map.txt /content/data/\n",
        "#Upload your images and coco dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92kgn8c-Avpg"
      },
      "source": [
        "## Installing requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Restart of google collab session required\n",
        "!pip install tensorflow==2.15.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JeKPkXU3BRGw"
      },
      "outputs": [],
      "source": [
        "! rm -rf sample_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqCiRauOG-_Q"
      },
      "outputs": [],
      "source": [
        "!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n",
        "!echo \"deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\" | sudo tee /etc/apt/sources.list.d/coral-edgetpu.list\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install edgetpu-compiler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRYGXzpiuyeG"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/tensorflow/models.git\n",
        "\n",
        "%cd models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "!cp object_detection/packages/tf2/setup.py .\n",
        "!python -m pip install .\n",
        "%cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cS3wMmOnuTZl"
      },
      "outputs": [],
      "source": [
        "!pip install tflite\n",
        "!pip install tflite_runtime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yx70rU7__M5L"
      },
      "outputs": [],
      "source": [
        "!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
        "\n",
        "!tar -xvf ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
        "!rm ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
        "\n",
        "model = \"ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i180FOr_sNX6"
      },
      "outputs": [],
      "source": [
        "!mkdir model_tfrecord\n",
        "!mkdir model_trained\n",
        "!mkdir model_exported"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MW9B1QzSACBr"
      },
      "source": [
        "## Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KpYH8Mfy_y81"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import random\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ocbgpqxpxv8w"
      },
      "outputs": [],
      "source": [
        "def adjust_file_names(input_file):\n",
        "    \"\"\"Adjust file names in COCO dataset\n",
        "    - !!!Only needed if you use Label Studio!!!\n",
        "    - Removes the prefix \"image/\" from the names of the images\n",
        "    - Adds the category \"background\" with id=0\n",
        "    - Moves all other categories up by one id\n",
        "    - Exports customized COCO dataset xml\n",
        "\n",
        "    Args:\n",
        "      - input_file (str):   Original COCO dataset from Label Studio\n",
        "\n",
        "    Test:\n",
        "      - Check if background category has been added\n",
        "      - Check if the prefix is missing in the filename\n",
        "    \"\"\"\n",
        "\n",
        "    output_file=\"/content/data/labels.json\"\n",
        "    with open(input_file, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    data['categories'] = [{'id': 0, 'name': 'background'}] + data['categories']\n",
        "\n",
        "    for i, category in enumerate(data['categories'][1:], start=1):\n",
        "        category['id'] = i\n",
        "\n",
        "    for annotation in data['annotations']:\n",
        "        if annotation['category_id'] > 0:\n",
        "            annotation['category_id'] += 1\n",
        "\n",
        "    for image in data['images']:\n",
        "        image['file_name'] = os.path.basename(image['file_name'])\n",
        "\n",
        "    with open(output_file, 'w') as f:\n",
        "        json.dump(data, f)\n",
        "\n",
        "    print(f\"Die Datei {input_file} wurde erfolgreich angepasst und gespeichert als {output_file}\")\n",
        "\n",
        "\n",
        "\n",
        "adjust_file_names(\"/content/data/result.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sc9RKv1J3X-b"
      },
      "outputs": [],
      "source": [
        "def split_coco_dataset(image_dir, result_json, train_percent, val_percent, test_percent):\n",
        "    \"\"\"Split COCO dataset\n",
        "    - Splits a COCO dataset into train, val, and test sets\n",
        "    - Adjust the input percentages according to your splitting needs\n",
        "\n",
        "    Args:\n",
        "      - image_dir (str):      Directory containing the images.\n",
        "      - result_json (str):    Path to the COCO JSON file.\n",
        "      - train_percent (int):  Percentage of images used for training\n",
        "      - val_percent (int):    Percentage of images used for validation\n",
        "      - test_percent (int):   Percentage of images used for testing\n",
        "\n",
        "    Test:\n",
        "      - Check whether the three different json have been created in \"/content/data\"\n",
        "    \"\"\"\n",
        "\n",
        "    with open(result_json, 'r') as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    images = data['images']\n",
        "    annotations = data['annotations']\n",
        "\n",
        "    random.shuffle(images)\n",
        "    total_images = len(images)\n",
        "    train_end = int(total_images * train_percent / 100)\n",
        "    val_end = train_end + int(total_images * val_percent / 100)\n",
        "\n",
        "    train_images = images[:train_end]\n",
        "    val_images = images[train_end:val_end]\n",
        "    test_images = images[val_end:]\n",
        "\n",
        "\n",
        "\n",
        "    def filter_annotations(selected_images):\n",
        "        image_ids = set([img['id'] for img in selected_images])\n",
        "        return [ann for ann in annotations if ann['image_id'] in image_ids]\n",
        "\n",
        "\n",
        "\n",
        "    def save_coco_file(images, annotations, filename):\n",
        "        new_data = {\n",
        "            'images': images,\n",
        "            'annotations': annotations,\n",
        "            'categories': data['categories']\n",
        "        }\n",
        "        with open(filename, 'w') as file:\n",
        "            json.dump(new_data, file)\n",
        "\n",
        "        print(f\"Exported splitted COCO dataset to {filename}\")\n",
        "\n",
        "    train_annotations = filter_annotations(train_images)\n",
        "    val_annotations = filter_annotations(val_images)\n",
        "    test_annotations = filter_annotations(test_images)\n",
        "\n",
        "    save_coco_file(train_images, train_annotations, \"/content/data/train.json\")\n",
        "    save_coco_file(val_images, val_annotations, \"/content/data/val.json\")\n",
        "    save_coco_file(test_images, test_annotations, \"/content/data/test.json\")\n",
        "\n",
        "\n",
        "\n",
        "split_coco_dataset('/content/data/images', '/content/data/labels.json', 70, 20, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLAUNlBp1Dt_"
      },
      "outputs": [],
      "source": [
        "!rm -f /content/tfrecord/*\n",
        "%cd models\n",
        "!python research/object_detection/dataset_tools/create_coco_tf_record.py --logtostderr \\\n",
        "  --train_image_dir=\"/content/data/images\" \\\n",
        "  --val_image_dir=\"/content/data/images\" \\\n",
        "  --test_image_dir=\"/content/data/images\" \\\n",
        "  --train_annotations_file=\"/content/data/train.json\" \\\n",
        "  --val_annotations_file=\"/content/data/val.json\" \\\n",
        "  --testdev_annotations_file=\"/content/data/test.json\" \\\n",
        "  --output_dir=\"/content/model_tfrecord/\" \\\n",
        "%cd /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rLZSwqI1xT9L"
      },
      "outputs": [],
      "source": [
        "def update_config_file(config_path, fine_tune_checkpoint, train_record_path, val_record_path, label_map_path, batch_size, steps, num_classes):\n",
        "    \"\"\"Update config file\n",
        "    - !!!If you change the model, the replacement functions must be adapted accordingly!!!\n",
        "    - Adjusts the values and paths from the original model config and outputs a new \"pipeline.config\"\n",
        "\n",
        "    Args:\n",
        "      - config_path (str):          Path to the .config file to be updated\n",
        "      - fine_tune_checkpoint (str): Path to the pre-trained model checkpoint\n",
        "      - train_record_path (str):    Path to the training TFRecord file\n",
        "      - val_record_path (str):      Path to the validation TFRecord file\n",
        "      - label_map_path (str):       Path to the label map file\n",
        "      - batch_size (int):           Number of batch count\n",
        "      - steps (int):                Number of streps\n",
        "      - num_classes (int):          Number of classes\n",
        "\n",
        "    Test:\n",
        "      - Check whether the paths and values in the output \"pipeline.config\" are correct\n",
        "    \"\"\"\n",
        "\n",
        "    with open(config_path) as f:\n",
        "        config = f.read()\n",
        "\n",
        "    config = config.replace('fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED\"', f'fine_tune_checkpoint: \"{fine_tune_checkpoint}\"')\n",
        "    config = config.replace('input_path: \"PATH_TO_BE_CONFIGURED\"', f'input_path: \"{train_record_path}\"')\n",
        "    config = config.replace('input_path: \"PATH_TO_BE_CONFIGURED/val2017-?????-of-00032.tfrecord\"', f'input_path: \"{val_record_path}\"')\n",
        "    config = config.replace('label_map_path: \"PATH_TO_BE_CONFIGURED\"', f'label_map_path: \"{label_map_path}\"')\n",
        "    config = config.replace('batch_size: 128', f'batch_size: {batch_size}')\n",
        "    config = config.replace('total_steps: 50000', f'total_steps: {steps}')\n",
        "    config = config.replace('num_steps: 50000', f'num_steps: {steps}')\n",
        "    config = config.replace('num_classes: 90', f'num_classes: {num_classes}')\n",
        "    config = config.replace('fine_tune_checkpoint_type: \"classification\"', f'fine_tune_checkpoint_type: \"detection\"')\n",
        "\n",
        "    with open(\"/content/pipeline.config\", 'w') as f:\n",
        "        f.write(config)\n",
        "\n",
        "    print(f\"{config_path} was updated with the specified parameters\")\n",
        "\n",
        "\n",
        "\n",
        "update_config_file(\n",
        "    config_path='/content/' + model + '/pipeline.config',\n",
        "    fine_tune_checkpoint='/content/' + model + '/checkpoint/ckpt-0',\n",
        "    train_record_path='/content/model_tfrecord/coco_train*',\n",
        "    val_record_path='/content/model_tfrecord/coco_val*',\n",
        "    label_map_path='/content/data/label_map.txt',\n",
        "    batch_size=4,\n",
        "    steps=5000,\n",
        "    num_classes=9\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sXfrMrD2UO92"
      },
      "outputs": [],
      "source": [
        "# Source: https://github.com/tensorflow/models/issues/11099#issuecomment-1902615454\n",
        "\n",
        "import shutil\n",
        "import re\n",
        "\n",
        "original_path = '/usr/local/lib/python3.10/dist-packages/tf_slim/data/tfexample_decoder.py'\n",
        "with open(original_path, 'r') as file:\n",
        "  content = file.read()\n",
        "  content = re.sub(r'import abc', 'import tensorflow as tf\\n\\nimport abc', content)\n",
        "  content = re.sub(r'control_flow_ops.case', 'tf.case', content)\n",
        "  content = re.sub(r'control_flow_ops.cond', 'tf.compat.v1.cond', content)\n",
        "with open(original_path, 'w') as file:\n",
        "  file.write(content)\n",
        "\n",
        "print(f\"File {original_path} fixed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZclMbyqD5QjA"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /content/trained"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LeyQDqqAC5oh"
      },
      "outputs": [],
      "source": [
        "%cd /content/models/research/object_detection\n",
        "!python model_main_tf2.py --model_dir /content/model_trained --pipeline_config_path /content/pipeline.config\n",
        "%cd /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tvzFP7sLRrFm"
      },
      "outputs": [],
      "source": [
        "%cd models/research/object_detection\n",
        "!python export_tflite_graph_tf2.py --output_directory /content/model_exported --pipeline_config_path /content/pipeline.config --trained_checkpoint_dir /content/model_trained/\n",
        "%cd /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qsl_xrGtyUm"
      },
      "outputs": [],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_saved_model(\"/content/model_exported/saved_model\")\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]\n",
        "\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open('/content/model_tensorflow.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "print(\"Exported and converted Tensorflow model into model_tensorflow.tflite\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gx4ZGYgXASp_"
      },
      "source": [
        "## Post-training quantization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-l4bFrr7cak"
      },
      "outputs": [],
      "source": [
        "def representative_data_gen():\n",
        "    \"\"\"Loads representative dataset\n",
        "    - Loads the images from the COCO dataset train.json for the quantization process\n",
        "\n",
        "    Test:\n",
        "      - Check whether the conversion process was successful\n",
        "    \"\"\"\n",
        "\n",
        "    annotation_file = '/content/data/test.json'\n",
        "    image_dir = '/content/data/images'\n",
        "\n",
        "    with open(annotation_file, 'r') as f:\n",
        "        annotations_data = json.load(f)\n",
        "\n",
        "    for image_info in annotations_data['images']:\n",
        "        image_path = os.path.join(image_dir, image_info['file_name'])\n",
        "        image = np.array(Image.open(image_path))\n",
        "        image = tf.image.resize(image, [320, 320])\n",
        "        image = tf.cast(image / 255., tf.float32)\n",
        "        image = tf.expand_dims(image, 0)\n",
        "        yield [image]\n",
        "\n",
        "\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(\"/content/model_exported/saved_model\")\n",
        "\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_data_gen\n",
        "\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.target_spec.supported_types = [tf.int8]\n",
        "\n",
        "converter.inference_input_type = tf.int8\n",
        "converter.inference_output_type = tf.float32\n",
        "\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open('/content/model_quant.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)\n",
        "\n",
        "print(\"Exported and quantized model into model_quant.tflite\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7HeMcjDAcuH"
      },
      "source": [
        "## Conversion to an EdgeTPU model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56E1O_zlHXqR"
      },
      "outputs": [],
      "source": [
        "!edgetpu_compiler /content/model_quant.tflite"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
